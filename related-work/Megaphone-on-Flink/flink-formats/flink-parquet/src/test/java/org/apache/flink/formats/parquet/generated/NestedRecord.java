/**
 * Autogenerated by Avro
 *
 * DO NOT EDIT DIRECTLY
 */
package org.apache.flink.formats.parquet.generated;

import org.apache.avro.generic.GenericArray;
import org.apache.avro.specific.SpecificData;
import org.apache.avro.util.Utf8;
import org.apache.avro.message.BinaryMessageEncoder;
import org.apache.avro.message.BinaryMessageDecoder;
import org.apache.avro.message.SchemaStore;

@org.apache.avro.specific.AvroGenerated
public class NestedRecord extends org.apache.avro.specific.SpecificRecordBase implements org.apache.avro.specific.SpecificRecord {
  private static final long serialVersionUID = 6280563285893134835L;
  public static final org.apache.avro.Schema SCHEMA$ = new org.apache.avro.Schema.Parser().parse("{\"type\":\"record\",\"name\":\"NestedRecord\",\"namespace\":\"org.apache.flink.formats.parquet.generated\",\"fields\":[{\"name\":\"foo\",\"type\":[\"null\",\"long\"],\"default\":null},{\"name\":\"spamMap\",\"type\":[\"null\",{\"type\":\"map\",\"values\":\"string\"}],\"default\":null},{\"name\":\"bar\",\"type\":[\"null\",{\"type\":\"record\",\"name\":\"Bar\",\"fields\":[{\"name\":\"spam\",\"type\":[\"null\",\"long\"],\"default\":null}]}],\"default\":null},{\"name\":\"arr\",\"type\":[\"null\",{\"type\":\"array\",\"items\":\"long\"}],\"default\":null},{\"name\":\"strArray\",\"type\":[\"null\",{\"type\":\"array\",\"items\":\"string\"}],\"default\":null},{\"name\":\"nestedMap\",\"type\":[\"null\",{\"type\":\"map\",\"values\":{\"type\":\"record\",\"name\":\"MapItem\",\"fields\":[{\"name\":\"type\",\"type\":[\"null\",\"string\"]},{\"name\":\"value\",\"type\":[\"null\",\"string\"]}]}}],\"default\":null},{\"name\":\"nestedArray\",\"type\":[\"null\",{\"type\":\"array\",\"items\":{\"type\":\"record\",\"name\":\"ArrayItem\",\"fields\":[{\"name\":\"type\",\"type\":\"string\"},{\"name\":\"value\",\"type\":\"long\"}]}}],\"default\":null}],\"schema_id\":1}");
  public static org.apache.avro.Schema getClassSchema() { return SCHEMA$; }

  private static SpecificData MODEL$ = new SpecificData();

  private static final BinaryMessageEncoder<NestedRecord> ENCODER =
      new BinaryMessageEncoder<NestedRecord>(MODEL$, SCHEMA$);

  private static final BinaryMessageDecoder<NestedRecord> DECODER =
      new BinaryMessageDecoder<NestedRecord>(MODEL$, SCHEMA$);

  /**
   * Return the BinaryMessageEncoder instance used by this class.
   * @return the message encoder used by this class
   */
  public static BinaryMessageEncoder<NestedRecord> getEncoder() {
    return ENCODER;
  }

  /**
   * Return the BinaryMessageDecoder instance used by this class.
   * @return the message decoder used by this class
   */
  public static BinaryMessageDecoder<NestedRecord> getDecoder() {
    return DECODER;
  }

  /**
   * Create a new BinaryMessageDecoder instance for this class that uses the specified {@link SchemaStore}.
   * @param resolver a {@link SchemaStore} used to find schemas by fingerprint
   * @return a BinaryMessageDecoder instance for this class backed by the given SchemaStore
   */
  public static BinaryMessageDecoder<NestedRecord> createDecoder(SchemaStore resolver) {
    return new BinaryMessageDecoder<NestedRecord>(MODEL$, SCHEMA$, resolver);
  }

  /**
   * Serializes this NestedRecord to a ByteBuffer.
   * @return a buffer holding the serialized data for this instance
   * @throws java.io.IOException if this instance could not be serialized
   */
  public java.nio.ByteBuffer toByteBuffer() throws java.io.IOException {
    return ENCODER.encode(this);
  }

  /**
   * Deserializes a NestedRecord from a ByteBuffer.
   * @param b a byte buffer holding serialized data for an instance of this class
   * @return a NestedRecord instance decoded from the given buffer
   * @throws java.io.IOException if the given bytes could not be deserialized into an instance of this class
   */
  public static NestedRecord fromByteBuffer(
      java.nio.ByteBuffer b) throws java.io.IOException {
    return DECODER.decode(b);
  }

   private java.lang.Long foo;
   private java.util.Map<java.lang.CharSequence,java.lang.CharSequence> spamMap;
   private org.apache.flink.formats.parquet.generated.Bar bar;
   private java.util.List<java.lang.Long> arr;
   private java.util.List<java.lang.CharSequence> strArray;
   private java.util.Map<java.lang.CharSequence,org.apache.flink.formats.parquet.generated.MapItem> nestedMap;
   private java.util.List<org.apache.flink.formats.parquet.generated.ArrayItem> nestedArray;

  /**
   * Default constructor.  Note that this does not initialize fields
   * to their default values from the schema.  If that is desired then
   * one should use <code>newBuilder()</code>.
   */
  public NestedRecord() {}

  /**
   * All-args constructor.
   * @param foo The new value for foo
   * @param spamMap The new value for spamMap
   * @param bar The new value for bar
   * @param arr The new value for arr
   * @param strArray The new value for strArray
   * @param nestedMap The new value for nestedMap
   * @param nestedArray The new value for nestedArray
   */
  public NestedRecord(java.lang.Long foo, java.util.Map<java.lang.CharSequence,java.lang.CharSequence> spamMap, org.apache.flink.formats.parquet.generated.Bar bar, java.util.List<java.lang.Long> arr, java.util.List<java.lang.CharSequence> strArray, java.util.Map<java.lang.CharSequence,org.apache.flink.formats.parquet.generated.MapItem> nestedMap, java.util.List<org.apache.flink.formats.parquet.generated.ArrayItem> nestedArray) {
    this.foo = foo;
    this.spamMap = spamMap;
    this.bar = bar;
    this.arr = arr;
    this.strArray = strArray;
    this.nestedMap = nestedMap;
    this.nestedArray = nestedArray;
  }

  public org.apache.avro.specific.SpecificData getSpecificData() { return MODEL$; }
  public org.apache.avro.Schema getSchema() { return SCHEMA$; }
  // Used by DatumWriter.  Applications should not call.
  public java.lang.Object get(int field$) {
    switch (field$) {
    case 0: return foo;
    case 1: return spamMap;
    case 2: return bar;
    case 3: return arr;
    case 4: return strArray;
    case 5: return nestedMap;
    case 6: return nestedArray;
    default: throw new IndexOutOfBoundsException("Invalid index: " + field$);
    }
  }

  // Used by DatumReader.  Applications should not call.
  @SuppressWarnings(value="unchecked")
  public void put(int field$, java.lang.Object value$) {
    switch (field$) {
    case 0: foo = (java.lang.Long)value$; break;
    case 1: spamMap = (java.util.Map<java.lang.CharSequence,java.lang.CharSequence>)value$; break;
    case 2: bar = (org.apache.flink.formats.parquet.generated.Bar)value$; break;
    case 3: arr = (java.util.List<java.lang.Long>)value$; break;
    case 4: strArray = (java.util.List<java.lang.CharSequence>)value$; break;
    case 5: nestedMap = (java.util.Map<java.lang.CharSequence,org.apache.flink.formats.parquet.generated.MapItem>)value$; break;
    case 6: nestedArray = (java.util.List<org.apache.flink.formats.parquet.generated.ArrayItem>)value$; break;
    default: throw new IndexOutOfBoundsException("Invalid index: " + field$);
    }
  }

  /**
   * Gets the value of the 'foo' field.
   * @return The value of the 'foo' field.
   */
  public java.lang.Long getFoo() {
    return foo;
  }


  /**
   * Sets the value of the 'foo' field.
   * @param value the value to set.
   */
  public void setFoo(java.lang.Long value) {
    this.foo = value;
  }

  /**
   * Gets the value of the 'spamMap' field.
   * @return The value of the 'spamMap' field.
   */
  public java.util.Map<java.lang.CharSequence,java.lang.CharSequence> getSpamMap() {
    return spamMap;
  }


  /**
   * Sets the value of the 'spamMap' field.
   * @param value the value to set.
   */
  public void setSpamMap(java.util.Map<java.lang.CharSequence,java.lang.CharSequence> value) {
    this.spamMap = value;
  }

  /**
   * Gets the value of the 'bar' field.
   * @return The value of the 'bar' field.
   */
  public org.apache.flink.formats.parquet.generated.Bar getBar() {
    return bar;
  }


  /**
   * Sets the value of the 'bar' field.
   * @param value the value to set.
   */
  public void setBar(org.apache.flink.formats.parquet.generated.Bar value) {
    this.bar = value;
  }

  /**
   * Gets the value of the 'arr' field.
   * @return The value of the 'arr' field.
   */
  public java.util.List<java.lang.Long> getArr() {
    return arr;
  }


  /**
   * Sets the value of the 'arr' field.
   * @param value the value to set.
   */
  public void setArr(java.util.List<java.lang.Long> value) {
    this.arr = value;
  }

  /**
   * Gets the value of the 'strArray' field.
   * @return The value of the 'strArray' field.
   */
  public java.util.List<java.lang.CharSequence> getStrArray() {
    return strArray;
  }


  /**
   * Sets the value of the 'strArray' field.
   * @param value the value to set.
   */
  public void setStrArray(java.util.List<java.lang.CharSequence> value) {
    this.strArray = value;
  }

  /**
   * Gets the value of the 'nestedMap' field.
   * @return The value of the 'nestedMap' field.
   */
  public java.util.Map<java.lang.CharSequence,org.apache.flink.formats.parquet.generated.MapItem> getNestedMap() {
    return nestedMap;
  }


  /**
   * Sets the value of the 'nestedMap' field.
   * @param value the value to set.
   */
  public void setNestedMap(java.util.Map<java.lang.CharSequence,org.apache.flink.formats.parquet.generated.MapItem> value) {
    this.nestedMap = value;
  }

  /**
   * Gets the value of the 'nestedArray' field.
   * @return The value of the 'nestedArray' field.
   */
  public java.util.List<org.apache.flink.formats.parquet.generated.ArrayItem> getNestedArray() {
    return nestedArray;
  }


  /**
   * Sets the value of the 'nestedArray' field.
   * @param value the value to set.
   */
  public void setNestedArray(java.util.List<org.apache.flink.formats.parquet.generated.ArrayItem> value) {
    this.nestedArray = value;
  }

  /**
   * Creates a new NestedRecord RecordBuilder.
   * @return A new NestedRecord RecordBuilder
   */
  public static org.apache.flink.formats.parquet.generated.NestedRecord.Builder newBuilder() {
    return new org.apache.flink.formats.parquet.generated.NestedRecord.Builder();
  }

  /**
   * Creates a new NestedRecord RecordBuilder by copying an existing Builder.
   * @param other The existing builder to copy.
   * @return A new NestedRecord RecordBuilder
   */
  public static org.apache.flink.formats.parquet.generated.NestedRecord.Builder newBuilder(org.apache.flink.formats.parquet.generated.NestedRecord.Builder other) {
    if (other == null) {
      return new org.apache.flink.formats.parquet.generated.NestedRecord.Builder();
    } else {
      return new org.apache.flink.formats.parquet.generated.NestedRecord.Builder(other);
    }
  }

  /**
   * Creates a new NestedRecord RecordBuilder by copying an existing NestedRecord instance.
   * @param other The existing instance to copy.
   * @return A new NestedRecord RecordBuilder
   */
  public static org.apache.flink.formats.parquet.generated.NestedRecord.Builder newBuilder(org.apache.flink.formats.parquet.generated.NestedRecord other) {
    if (other == null) {
      return new org.apache.flink.formats.parquet.generated.NestedRecord.Builder();
    } else {
      return new org.apache.flink.formats.parquet.generated.NestedRecord.Builder(other);
    }
  }

  /**
   * RecordBuilder for NestedRecord instances.
   */
  @org.apache.avro.specific.AvroGenerated
  public static class Builder extends org.apache.avro.specific.SpecificRecordBuilderBase<NestedRecord>
    implements org.apache.avro.data.RecordBuilder<NestedRecord> {

    private java.lang.Long foo;
    private java.util.Map<java.lang.CharSequence,java.lang.CharSequence> spamMap;
    private org.apache.flink.formats.parquet.generated.Bar bar;
    private org.apache.flink.formats.parquet.generated.Bar.Builder barBuilder;
    private java.util.List<java.lang.Long> arr;
    private java.util.List<java.lang.CharSequence> strArray;
    private java.util.Map<java.lang.CharSequence,org.apache.flink.formats.parquet.generated.MapItem> nestedMap;
    private java.util.List<org.apache.flink.formats.parquet.generated.ArrayItem> nestedArray;

    /** Creates a new Builder */
    private Builder() {
      super(SCHEMA$);
    }

    /**
     * Creates a Builder by copying an existing Builder.
     * @param other The existing Builder to copy.
     */
    private Builder(org.apache.flink.formats.parquet.generated.NestedRecord.Builder other) {
      super(other);
      if (isValidValue(fields()[0], other.foo)) {
        this.foo = data().deepCopy(fields()[0].schema(), other.foo);
        fieldSetFlags()[0] = other.fieldSetFlags()[0];
      }
      if (isValidValue(fields()[1], other.spamMap)) {
        this.spamMap = data().deepCopy(fields()[1].schema(), other.spamMap);
        fieldSetFlags()[1] = other.fieldSetFlags()[1];
      }
      if (isValidValue(fields()[2], other.bar)) {
        this.bar = data().deepCopy(fields()[2].schema(), other.bar);
        fieldSetFlags()[2] = other.fieldSetFlags()[2];
      }
      if (other.hasBarBuilder()) {
        this.barBuilder = org.apache.flink.formats.parquet.generated.Bar.newBuilder(other.getBarBuilder());
      }
      if (isValidValue(fields()[3], other.arr)) {
        this.arr = data().deepCopy(fields()[3].schema(), other.arr);
        fieldSetFlags()[3] = other.fieldSetFlags()[3];
      }
      if (isValidValue(fields()[4], other.strArray)) {
        this.strArray = data().deepCopy(fields()[4].schema(), other.strArray);
        fieldSetFlags()[4] = other.fieldSetFlags()[4];
      }
      if (isValidValue(fields()[5], other.nestedMap)) {
        this.nestedMap = data().deepCopy(fields()[5].schema(), other.nestedMap);
        fieldSetFlags()[5] = other.fieldSetFlags()[5];
      }
      if (isValidValue(fields()[6], other.nestedArray)) {
        this.nestedArray = data().deepCopy(fields()[6].schema(), other.nestedArray);
        fieldSetFlags()[6] = other.fieldSetFlags()[6];
      }
    }

    /**
     * Creates a Builder by copying an existing NestedRecord instance
     * @param other The existing instance to copy.
     */
    private Builder(org.apache.flink.formats.parquet.generated.NestedRecord other) {
      super(SCHEMA$);
      if (isValidValue(fields()[0], other.foo)) {
        this.foo = data().deepCopy(fields()[0].schema(), other.foo);
        fieldSetFlags()[0] = true;
      }
      if (isValidValue(fields()[1], other.spamMap)) {
        this.spamMap = data().deepCopy(fields()[1].schema(), other.spamMap);
        fieldSetFlags()[1] = true;
      }
      if (isValidValue(fields()[2], other.bar)) {
        this.bar = data().deepCopy(fields()[2].schema(), other.bar);
        fieldSetFlags()[2] = true;
      }
      this.barBuilder = null;
      if (isValidValue(fields()[3], other.arr)) {
        this.arr = data().deepCopy(fields()[3].schema(), other.arr);
        fieldSetFlags()[3] = true;
      }
      if (isValidValue(fields()[4], other.strArray)) {
        this.strArray = data().deepCopy(fields()[4].schema(), other.strArray);
        fieldSetFlags()[4] = true;
      }
      if (isValidValue(fields()[5], other.nestedMap)) {
        this.nestedMap = data().deepCopy(fields()[5].schema(), other.nestedMap);
        fieldSetFlags()[5] = true;
      }
      if (isValidValue(fields()[6], other.nestedArray)) {
        this.nestedArray = data().deepCopy(fields()[6].schema(), other.nestedArray);
        fieldSetFlags()[6] = true;
      }
    }

    /**
      * Gets the value of the 'foo' field.
      * @return The value.
      */
    public java.lang.Long getFoo() {
      return foo;
    }


    /**
      * Sets the value of the 'foo' field.
      * @param value The value of 'foo'.
      * @return This builder.
      */
    public org.apache.flink.formats.parquet.generated.NestedRecord.Builder setFoo(java.lang.Long value) {
      validate(fields()[0], value);
      this.foo = value;
      fieldSetFlags()[0] = true;
      return this;
    }

    /**
      * Checks whether the 'foo' field has been set.
      * @return True if the 'foo' field has been set, false otherwise.
      */
    public boolean hasFoo() {
      return fieldSetFlags()[0];
    }


    /**
      * Clears the value of the 'foo' field.
      * @return This builder.
      */
    public org.apache.flink.formats.parquet.generated.NestedRecord.Builder clearFoo() {
      foo = null;
      fieldSetFlags()[0] = false;
      return this;
    }

    /**
      * Gets the value of the 'spamMap' field.
      * @return The value.
      */
    public java.util.Map<java.lang.CharSequence,java.lang.CharSequence> getSpamMap() {
      return spamMap;
    }


    /**
      * Sets the value of the 'spamMap' field.
      * @param value The value of 'spamMap'.
      * @return This builder.
      */
    public org.apache.flink.formats.parquet.generated.NestedRecord.Builder setSpamMap(java.util.Map<java.lang.CharSequence,java.lang.CharSequence> value) {
      validate(fields()[1], value);
      this.spamMap = value;
      fieldSetFlags()[1] = true;
      return this;
    }

    /**
      * Checks whether the 'spamMap' field has been set.
      * @return True if the 'spamMap' field has been set, false otherwise.
      */
    public boolean hasSpamMap() {
      return fieldSetFlags()[1];
    }


    /**
      * Clears the value of the 'spamMap' field.
      * @return This builder.
      */
    public org.apache.flink.formats.parquet.generated.NestedRecord.Builder clearSpamMap() {
      spamMap = null;
      fieldSetFlags()[1] = false;
      return this;
    }

    /**
      * Gets the value of the 'bar' field.
      * @return The value.
      */
    public org.apache.flink.formats.parquet.generated.Bar getBar() {
      return bar;
    }


    /**
      * Sets the value of the 'bar' field.
      * @param value The value of 'bar'.
      * @return This builder.
      */
    public org.apache.flink.formats.parquet.generated.NestedRecord.Builder setBar(org.apache.flink.formats.parquet.generated.Bar value) {
      validate(fields()[2], value);
      this.barBuilder = null;
      this.bar = value;
      fieldSetFlags()[2] = true;
      return this;
    }

    /**
      * Checks whether the 'bar' field has been set.
      * @return True if the 'bar' field has been set, false otherwise.
      */
    public boolean hasBar() {
      return fieldSetFlags()[2];
    }

    /**
     * Gets the Builder instance for the 'bar' field and creates one if it doesn't exist yet.
     * @return This builder.
     */
    public org.apache.flink.formats.parquet.generated.Bar.Builder getBarBuilder() {
      if (barBuilder == null) {
        if (hasBar()) {
          setBarBuilder(org.apache.flink.formats.parquet.generated.Bar.newBuilder(bar));
        } else {
          setBarBuilder(org.apache.flink.formats.parquet.generated.Bar.newBuilder());
        }
      }
      return barBuilder;
    }

    /**
     * Sets the Builder instance for the 'bar' field
     * @param value The builder instance that must be set.
     * @return This builder.
     */
    public org.apache.flink.formats.parquet.generated.NestedRecord.Builder setBarBuilder(org.apache.flink.formats.parquet.generated.Bar.Builder value) {
      clearBar();
      barBuilder = value;
      return this;
    }

    /**
     * Checks whether the 'bar' field has an active Builder instance
     * @return True if the 'bar' field has an active Builder instance
     */
    public boolean hasBarBuilder() {
      return barBuilder != null;
    }

    /**
      * Clears the value of the 'bar' field.
      * @return This builder.
      */
    public org.apache.flink.formats.parquet.generated.NestedRecord.Builder clearBar() {
      bar = null;
      barBuilder = null;
      fieldSetFlags()[2] = false;
      return this;
    }

    /**
      * Gets the value of the 'arr' field.
      * @return The value.
      */
    public java.util.List<java.lang.Long> getArr() {
      return arr;
    }


    /**
      * Sets the value of the 'arr' field.
      * @param value The value of 'arr'.
      * @return This builder.
      */
    public org.apache.flink.formats.parquet.generated.NestedRecord.Builder setArr(java.util.List<java.lang.Long> value) {
      validate(fields()[3], value);
      this.arr = value;
      fieldSetFlags()[3] = true;
      return this;
    }

    /**
      * Checks whether the 'arr' field has been set.
      * @return True if the 'arr' field has been set, false otherwise.
      */
    public boolean hasArr() {
      return fieldSetFlags()[3];
    }


    /**
      * Clears the value of the 'arr' field.
      * @return This builder.
      */
    public org.apache.flink.formats.parquet.generated.NestedRecord.Builder clearArr() {
      arr = null;
      fieldSetFlags()[3] = false;
      return this;
    }

    /**
      * Gets the value of the 'strArray' field.
      * @return The value.
      */
    public java.util.List<java.lang.CharSequence> getStrArray() {
      return strArray;
    }


    /**
      * Sets the value of the 'strArray' field.
      * @param value The value of 'strArray'.
      * @return This builder.
      */
    public org.apache.flink.formats.parquet.generated.NestedRecord.Builder setStrArray(java.util.List<java.lang.CharSequence> value) {
      validate(fields()[4], value);
      this.strArray = value;
      fieldSetFlags()[4] = true;
      return this;
    }

    /**
      * Checks whether the 'strArray' field has been set.
      * @return True if the 'strArray' field has been set, false otherwise.
      */
    public boolean hasStrArray() {
      return fieldSetFlags()[4];
    }


    /**
      * Clears the value of the 'strArray' field.
      * @return This builder.
      */
    public org.apache.flink.formats.parquet.generated.NestedRecord.Builder clearStrArray() {
      strArray = null;
      fieldSetFlags()[4] = false;
      return this;
    }

    /**
      * Gets the value of the 'nestedMap' field.
      * @return The value.
      */
    public java.util.Map<java.lang.CharSequence,org.apache.flink.formats.parquet.generated.MapItem> getNestedMap() {
      return nestedMap;
    }


    /**
      * Sets the value of the 'nestedMap' field.
      * @param value The value of 'nestedMap'.
      * @return This builder.
      */
    public org.apache.flink.formats.parquet.generated.NestedRecord.Builder setNestedMap(java.util.Map<java.lang.CharSequence,org.apache.flink.formats.parquet.generated.MapItem> value) {
      validate(fields()[5], value);
      this.nestedMap = value;
      fieldSetFlags()[5] = true;
      return this;
    }

    /**
      * Checks whether the 'nestedMap' field has been set.
      * @return True if the 'nestedMap' field has been set, false otherwise.
      */
    public boolean hasNestedMap() {
      return fieldSetFlags()[5];
    }


    /**
      * Clears the value of the 'nestedMap' field.
      * @return This builder.
      */
    public org.apache.flink.formats.parquet.generated.NestedRecord.Builder clearNestedMap() {
      nestedMap = null;
      fieldSetFlags()[5] = false;
      return this;
    }

    /**
      * Gets the value of the 'nestedArray' field.
      * @return The value.
      */
    public java.util.List<org.apache.flink.formats.parquet.generated.ArrayItem> getNestedArray() {
      return nestedArray;
    }


    /**
      * Sets the value of the 'nestedArray' field.
      * @param value The value of 'nestedArray'.
      * @return This builder.
      */
    public org.apache.flink.formats.parquet.generated.NestedRecord.Builder setNestedArray(java.util.List<org.apache.flink.formats.parquet.generated.ArrayItem> value) {
      validate(fields()[6], value);
      this.nestedArray = value;
      fieldSetFlags()[6] = true;
      return this;
    }

    /**
      * Checks whether the 'nestedArray' field has been set.
      * @return True if the 'nestedArray' field has been set, false otherwise.
      */
    public boolean hasNestedArray() {
      return fieldSetFlags()[6];
    }


    /**
      * Clears the value of the 'nestedArray' field.
      * @return This builder.
      */
    public org.apache.flink.formats.parquet.generated.NestedRecord.Builder clearNestedArray() {
      nestedArray = null;
      fieldSetFlags()[6] = false;
      return this;
    }

    @Override
    @SuppressWarnings("unchecked")
    public NestedRecord build() {
      try {
        NestedRecord record = new NestedRecord();
        record.foo = fieldSetFlags()[0] ? this.foo : (java.lang.Long) defaultValue(fields()[0]);
        record.spamMap = fieldSetFlags()[1] ? this.spamMap : (java.util.Map<java.lang.CharSequence,java.lang.CharSequence>) defaultValue(fields()[1]);
        if (barBuilder != null) {
          try {
            record.bar = this.barBuilder.build();
          } catch (org.apache.avro.AvroMissingFieldException e) {
            e.addParentField(record.getSchema().getField("bar"));
            throw e;
          }
        } else {
          record.bar = fieldSetFlags()[2] ? this.bar : (org.apache.flink.formats.parquet.generated.Bar) defaultValue(fields()[2]);
        }
        record.arr = fieldSetFlags()[3] ? this.arr : (java.util.List<java.lang.Long>) defaultValue(fields()[3]);
        record.strArray = fieldSetFlags()[4] ? this.strArray : (java.util.List<java.lang.CharSequence>) defaultValue(fields()[4]);
        record.nestedMap = fieldSetFlags()[5] ? this.nestedMap : (java.util.Map<java.lang.CharSequence,org.apache.flink.formats.parquet.generated.MapItem>) defaultValue(fields()[5]);
        record.nestedArray = fieldSetFlags()[6] ? this.nestedArray : (java.util.List<org.apache.flink.formats.parquet.generated.ArrayItem>) defaultValue(fields()[6]);
        return record;
      } catch (org.apache.avro.AvroMissingFieldException e) {
        throw e;
      } catch (java.lang.Exception e) {
        throw new org.apache.avro.AvroRuntimeException(e);
      }
    }
  }

  @SuppressWarnings("unchecked")
  private static final org.apache.avro.io.DatumWriter<NestedRecord>
    WRITER$ = (org.apache.avro.io.DatumWriter<NestedRecord>)MODEL$.createDatumWriter(SCHEMA$);

  @Override public void writeExternal(java.io.ObjectOutput out)
    throws java.io.IOException {
    WRITER$.write(this, SpecificData.getEncoder(out));
  }

  @SuppressWarnings("unchecked")
  private static final org.apache.avro.io.DatumReader<NestedRecord>
    READER$ = (org.apache.avro.io.DatumReader<NestedRecord>)MODEL$.createDatumReader(SCHEMA$);

  @Override public void readExternal(java.io.ObjectInput in)
    throws java.io.IOException {
    READER$.read(this, SpecificData.getDecoder(in));
  }

  @Override protected boolean hasCustomCoders() { return true; }

  @Override public void customEncode(org.apache.avro.io.Encoder out)
    throws java.io.IOException
  {
    if (this.foo == null) {
      out.writeIndex(0);
      out.writeNull();
    } else {
      out.writeIndex(1);
      out.writeLong(this.foo);
    }

    if (this.spamMap == null) {
      out.writeIndex(0);
      out.writeNull();
    } else {
      out.writeIndex(1);
      long size0 = this.spamMap.size();
      out.writeMapStart();
      out.setItemCount(size0);
      long actualSize0 = 0;
      for (java.util.Map.Entry<java.lang.CharSequence, java.lang.CharSequence> e0: this.spamMap.entrySet()) {
        actualSize0++;
        out.startItem();
        out.writeString(e0.getKey());
        java.lang.CharSequence v0 = e0.getValue();
        out.writeString(v0);
      }
      out.writeMapEnd();
      if (actualSize0 != size0)
      throw new java.util.ConcurrentModificationException("Map-size written was " + size0 + ", but element count was " + actualSize0 + ".");
    }

    if (this.bar == null) {
      out.writeIndex(0);
      out.writeNull();
    } else {
      out.writeIndex(1);
      this.bar.customEncode(out);
    }

    if (this.arr == null) {
      out.writeIndex(0);
      out.writeNull();
    } else {
      out.writeIndex(1);
      long size1 = this.arr.size();
      out.writeArrayStart();
      out.setItemCount(size1);
      long actualSize1 = 0;
      for (java.lang.Long e1: this.arr) {
        actualSize1++;
        out.startItem();
        out.writeLong(e1);
      }
      out.writeArrayEnd();
      if (actualSize1 != size1)
        throw new java.util.ConcurrentModificationException("Array-size written was " + size1 + ", but element count was " + actualSize1 + ".");
    }

    if (this.strArray == null) {
      out.writeIndex(0);
      out.writeNull();
    } else {
      out.writeIndex(1);
      long size2 = this.strArray.size();
      out.writeArrayStart();
      out.setItemCount(size2);
      long actualSize2 = 0;
      for (java.lang.CharSequence e2: this.strArray) {
        actualSize2++;
        out.startItem();
        out.writeString(e2);
      }
      out.writeArrayEnd();
      if (actualSize2 != size2)
        throw new java.util.ConcurrentModificationException("Array-size written was " + size2 + ", but element count was " + actualSize2 + ".");
    }

    if (this.nestedMap == null) {
      out.writeIndex(0);
      out.writeNull();
    } else {
      out.writeIndex(1);
      long size3 = this.nestedMap.size();
      out.writeMapStart();
      out.setItemCount(size3);
      long actualSize3 = 0;
      for (java.util.Map.Entry<java.lang.CharSequence, org.apache.flink.formats.parquet.generated.MapItem> e3: this.nestedMap.entrySet()) {
        actualSize3++;
        out.startItem();
        out.writeString(e3.getKey());
        org.apache.flink.formats.parquet.generated.MapItem v3 = e3.getValue();
        v3.customEncode(out);
      }
      out.writeMapEnd();
      if (actualSize3 != size3)
      throw new java.util.ConcurrentModificationException("Map-size written was " + size3 + ", but element count was " + actualSize3 + ".");
    }

    if (this.nestedArray == null) {
      out.writeIndex(0);
      out.writeNull();
    } else {
      out.writeIndex(1);
      long size4 = this.nestedArray.size();
      out.writeArrayStart();
      out.setItemCount(size4);
      long actualSize4 = 0;
      for (org.apache.flink.formats.parquet.generated.ArrayItem e4: this.nestedArray) {
        actualSize4++;
        out.startItem();
        e4.customEncode(out);
      }
      out.writeArrayEnd();
      if (actualSize4 != size4)
        throw new java.util.ConcurrentModificationException("Array-size written was " + size4 + ", but element count was " + actualSize4 + ".");
    }

  }

  @Override public void customDecode(org.apache.avro.io.ResolvingDecoder in)
    throws java.io.IOException
  {
    org.apache.avro.Schema.Field[] fieldOrder = in.readFieldOrderIfDiff();
    if (fieldOrder == null) {
      if (in.readIndex() != 1) {
        in.readNull();
        this.foo = null;
      } else {
        this.foo = in.readLong();
      }

      if (in.readIndex() != 1) {
        in.readNull();
        this.spamMap = null;
      } else {
        long size0 = in.readMapStart();
        java.util.Map<java.lang.CharSequence,java.lang.CharSequence> m0 = this.spamMap; // Need fresh name due to limitation of macro system
        if (m0 == null) {
          m0 = new java.util.HashMap<java.lang.CharSequence,java.lang.CharSequence>((int)size0);
          this.spamMap = m0;
        } else m0.clear();
        for ( ; 0 < size0; size0 = in.mapNext()) {
          for ( ; size0 != 0; size0--) {
            java.lang.CharSequence k0 = null;
            k0 = in.readString(k0 instanceof Utf8 ? (Utf8)k0 : null);
            java.lang.CharSequence v0 = null;
            v0 = in.readString(v0 instanceof Utf8 ? (Utf8)v0 : null);
            m0.put(k0, v0);
          }
        }
      }

      if (in.readIndex() != 1) {
        in.readNull();
        this.bar = null;
      } else {
        if (this.bar == null) {
          this.bar = new org.apache.flink.formats.parquet.generated.Bar();
        }
        this.bar.customDecode(in);
      }

      if (in.readIndex() != 1) {
        in.readNull();
        this.arr = null;
      } else {
        long size1 = in.readArrayStart();
        java.util.List<java.lang.Long> a1 = this.arr;
        if (a1 == null) {
          a1 = new SpecificData.Array<java.lang.Long>((int)size1, SCHEMA$.getField("arr").schema().getTypes().get(1));
          this.arr = a1;
        } else a1.clear();
        SpecificData.Array<java.lang.Long> ga1 = (a1 instanceof SpecificData.Array ? (SpecificData.Array<java.lang.Long>)a1 : null);
        for ( ; 0 < size1; size1 = in.arrayNext()) {
          for ( ; size1 != 0; size1--) {
            java.lang.Long e1 = (ga1 != null ? ga1.peek() : null);
            e1 = in.readLong();
            a1.add(e1);
          }
        }
      }

      if (in.readIndex() != 1) {
        in.readNull();
        this.strArray = null;
      } else {
        long size2 = in.readArrayStart();
        java.util.List<java.lang.CharSequence> a2 = this.strArray;
        if (a2 == null) {
          a2 = new SpecificData.Array<java.lang.CharSequence>((int)size2, SCHEMA$.getField("strArray").schema().getTypes().get(1));
          this.strArray = a2;
        } else a2.clear();
        SpecificData.Array<java.lang.CharSequence> ga2 = (a2 instanceof SpecificData.Array ? (SpecificData.Array<java.lang.CharSequence>)a2 : null);
        for ( ; 0 < size2; size2 = in.arrayNext()) {
          for ( ; size2 != 0; size2--) {
            java.lang.CharSequence e2 = (ga2 != null ? ga2.peek() : null);
            e2 = in.readString(e2 instanceof Utf8 ? (Utf8)e2 : null);
            a2.add(e2);
          }
        }
      }

      if (in.readIndex() != 1) {
        in.readNull();
        this.nestedMap = null;
      } else {
        long size3 = in.readMapStart();
        java.util.Map<java.lang.CharSequence,org.apache.flink.formats.parquet.generated.MapItem> m3 = this.nestedMap; // Need fresh name due to limitation of macro system
        if (m3 == null) {
          m3 = new java.util.HashMap<java.lang.CharSequence,org.apache.flink.formats.parquet.generated.MapItem>((int)size3);
          this.nestedMap = m3;
        } else m3.clear();
        for ( ; 0 < size3; size3 = in.mapNext()) {
          for ( ; size3 != 0; size3--) {
            java.lang.CharSequence k3 = null;
            k3 = in.readString(k3 instanceof Utf8 ? (Utf8)k3 : null);
            org.apache.flink.formats.parquet.generated.MapItem v3 = null;
            if (v3 == null) {
              v3 = new org.apache.flink.formats.parquet.generated.MapItem();
            }
            v3.customDecode(in);
            m3.put(k3, v3);
          }
        }
      }

      if (in.readIndex() != 1) {
        in.readNull();
        this.nestedArray = null;
      } else {
        long size4 = in.readArrayStart();
        java.util.List<org.apache.flink.formats.parquet.generated.ArrayItem> a4 = this.nestedArray;
        if (a4 == null) {
          a4 = new SpecificData.Array<org.apache.flink.formats.parquet.generated.ArrayItem>((int)size4, SCHEMA$.getField("nestedArray").schema().getTypes().get(1));
          this.nestedArray = a4;
        } else a4.clear();
        SpecificData.Array<org.apache.flink.formats.parquet.generated.ArrayItem> ga4 = (a4 instanceof SpecificData.Array ? (SpecificData.Array<org.apache.flink.formats.parquet.generated.ArrayItem>)a4 : null);
        for ( ; 0 < size4; size4 = in.arrayNext()) {
          for ( ; size4 != 0; size4--) {
            org.apache.flink.formats.parquet.generated.ArrayItem e4 = (ga4 != null ? ga4.peek() : null);
            if (e4 == null) {
              e4 = new org.apache.flink.formats.parquet.generated.ArrayItem();
            }
            e4.customDecode(in);
            a4.add(e4);
          }
        }
      }

    } else {
      for (int i = 0; i < 7; i++) {
        switch (fieldOrder[i].pos()) {
        case 0:
          if (in.readIndex() != 1) {
            in.readNull();
            this.foo = null;
          } else {
            this.foo = in.readLong();
          }
          break;

        case 1:
          if (in.readIndex() != 1) {
            in.readNull();
            this.spamMap = null;
          } else {
            long size0 = in.readMapStart();
            java.util.Map<java.lang.CharSequence,java.lang.CharSequence> m0 = this.spamMap; // Need fresh name due to limitation of macro system
            if (m0 == null) {
              m0 = new java.util.HashMap<java.lang.CharSequence,java.lang.CharSequence>((int)size0);
              this.spamMap = m0;
            } else m0.clear();
            for ( ; 0 < size0; size0 = in.mapNext()) {
              for ( ; size0 != 0; size0--) {
                java.lang.CharSequence k0 = null;
                k0 = in.readString(k0 instanceof Utf8 ? (Utf8)k0 : null);
                java.lang.CharSequence v0 = null;
                v0 = in.readString(v0 instanceof Utf8 ? (Utf8)v0 : null);
                m0.put(k0, v0);
              }
            }
          }
          break;

        case 2:
          if (in.readIndex() != 1) {
            in.readNull();
            this.bar = null;
          } else {
            if (this.bar == null) {
              this.bar = new org.apache.flink.formats.parquet.generated.Bar();
            }
            this.bar.customDecode(in);
          }
          break;

        case 3:
          if (in.readIndex() != 1) {
            in.readNull();
            this.arr = null;
          } else {
            long size1 = in.readArrayStart();
            java.util.List<java.lang.Long> a1 = this.arr;
            if (a1 == null) {
              a1 = new SpecificData.Array<java.lang.Long>((int)size1, SCHEMA$.getField("arr").schema().getTypes().get(1));
              this.arr = a1;
            } else a1.clear();
            SpecificData.Array<java.lang.Long> ga1 = (a1 instanceof SpecificData.Array ? (SpecificData.Array<java.lang.Long>)a1 : null);
            for ( ; 0 < size1; size1 = in.arrayNext()) {
              for ( ; size1 != 0; size1--) {
                java.lang.Long e1 = (ga1 != null ? ga1.peek() : null);
                e1 = in.readLong();
                a1.add(e1);
              }
            }
          }
          break;

        case 4:
          if (in.readIndex() != 1) {
            in.readNull();
            this.strArray = null;
          } else {
            long size2 = in.readArrayStart();
            java.util.List<java.lang.CharSequence> a2 = this.strArray;
            if (a2 == null) {
              a2 = new SpecificData.Array<java.lang.CharSequence>((int)size2, SCHEMA$.getField("strArray").schema().getTypes().get(1));
              this.strArray = a2;
            } else a2.clear();
            SpecificData.Array<java.lang.CharSequence> ga2 = (a2 instanceof SpecificData.Array ? (SpecificData.Array<java.lang.CharSequence>)a2 : null);
            for ( ; 0 < size2; size2 = in.arrayNext()) {
              for ( ; size2 != 0; size2--) {
                java.lang.CharSequence e2 = (ga2 != null ? ga2.peek() : null);
                e2 = in.readString(e2 instanceof Utf8 ? (Utf8)e2 : null);
                a2.add(e2);
              }
            }
          }
          break;

        case 5:
          if (in.readIndex() != 1) {
            in.readNull();
            this.nestedMap = null;
          } else {
            long size3 = in.readMapStart();
            java.util.Map<java.lang.CharSequence,org.apache.flink.formats.parquet.generated.MapItem> m3 = this.nestedMap; // Need fresh name due to limitation of macro system
            if (m3 == null) {
              m3 = new java.util.HashMap<java.lang.CharSequence,org.apache.flink.formats.parquet.generated.MapItem>((int)size3);
              this.nestedMap = m3;
            } else m3.clear();
            for ( ; 0 < size3; size3 = in.mapNext()) {
              for ( ; size3 != 0; size3--) {
                java.lang.CharSequence k3 = null;
                k3 = in.readString(k3 instanceof Utf8 ? (Utf8)k3 : null);
                org.apache.flink.formats.parquet.generated.MapItem v3 = null;
                if (v3 == null) {
                  v3 = new org.apache.flink.formats.parquet.generated.MapItem();
                }
                v3.customDecode(in);
                m3.put(k3, v3);
              }
            }
          }
          break;

        case 6:
          if (in.readIndex() != 1) {
            in.readNull();
            this.nestedArray = null;
          } else {
            long size4 = in.readArrayStart();
            java.util.List<org.apache.flink.formats.parquet.generated.ArrayItem> a4 = this.nestedArray;
            if (a4 == null) {
              a4 = new SpecificData.Array<org.apache.flink.formats.parquet.generated.ArrayItem>((int)size4, SCHEMA$.getField("nestedArray").schema().getTypes().get(1));
              this.nestedArray = a4;
            } else a4.clear();
            SpecificData.Array<org.apache.flink.formats.parquet.generated.ArrayItem> ga4 = (a4 instanceof SpecificData.Array ? (SpecificData.Array<org.apache.flink.formats.parquet.generated.ArrayItem>)a4 : null);
            for ( ; 0 < size4; size4 = in.arrayNext()) {
              for ( ; size4 != 0; size4--) {
                org.apache.flink.formats.parquet.generated.ArrayItem e4 = (ga4 != null ? ga4.peek() : null);
                if (e4 == null) {
                  e4 = new org.apache.flink.formats.parquet.generated.ArrayItem();
                }
                e4.customDecode(in);
                a4.add(e4);
              }
            }
          }
          break;

        default:
          throw new java.io.IOException("Corrupt ResolvingDecoder.");
        }
      }
    }
  }
}










